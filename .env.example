# Scalpel Configuration
# The model ID to request from the local OpenAI-compatible server (e.g., mistralrs)
# REQUIRED: Must match the model currently loaded in the server
SURR_SCALPEL_MODEL=NousResearch/Hermes-3-Llama-3.2-3B-GGUF

# The endpoint for the local model server
# Default: http://127.0.0.1:8111/v1/chat/completions
SURR_SCALPEL_ENDPOINT=http://127.0.0.1:8111/v1/chat/completions

# Max tokens for Scalpel responses
# Default: 1000
SURR_SCALPEL_MAX_TOKENS=1000

# Timeout for Scalpel requests in milliseconds
# Default: 120000 (2 minutes)
SURR_SCALPEL_TIMEOUT_MS=120000
